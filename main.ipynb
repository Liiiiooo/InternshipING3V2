{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI for cell recognition\n",
    "\n",
    "To help physicians we need to develop an AI that can classify cells into different types. For that, we have opened huge slide images, detected many cells, and extracted a feature vector for each of them.\n",
    "\n",
    "We also have asked the experts to annotate, for each cell class and many examples, if the cell belongs or not to the given class. Our data is organized as follows:\n",
    "- `annotations_{class}.csv` are CSVs for the three classes of interest, namely `(lymphocyte, lymphoplasmocyte, plasmocyte)`. The first column represents the cell index and the second a binary value (1 if the cell belongs to the class, else 0). \n",
    "- `cell_dataset.pkl` is the file containing the features and bounding boxes for the cells. We will not use the bounding boxes for now, they will be used later for visualization purposes. \n",
    "\n",
    "We now load the data and print some things:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features is a matrix of dimension (N,D)= (984007, 384)\n",
      "--------------------------------------------------------------------------------\n",
      "class 0 is lymphocyte\n",
      "number of annotations for class lymphocyte is 551\n",
      "number of positive annotations for class lymphocyte is 255\n",
      "--------------------------------------------------------------------------------\n",
      "class 1 is lymphoplasmocyte\n",
      "number of annotations for class lymphoplasmocyte is 468\n",
      "number of positive annotations for class lymphoplasmocyte is 138\n",
      "--------------------------------------------------------------------------------\n",
      "class 2 is plasmocyte\n",
      "number of annotations for class plasmocyte is 484\n",
      "number of positive annotations for class plasmocyte is 134\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import csv\n",
    "\n",
    "# load features\n",
    "with open('cell_dataset.pkl', 'rb') as f:\n",
    "    features = pickle.load(f)['feats']\n",
    "print('features is a matrix of dimension (N,D)=', features.shape)\n",
    "\n",
    "# load annotations for all classes\n",
    "classes = (\"lymphocyte\", \"lymphoplasmocyte\", \"plasmocyte\")\n",
    "annotations = {c: ([], []) for c in classes}  # init empty dict per class\n",
    "for i, c in enumerate(classes):\n",
    "    print(\"-\"*80)\n",
    "    print('class', i, 'is', c)\n",
    "    annotation_file = f\"annotations_{c}.csv\"\n",
    "    # load annotation file\n",
    "    with open(annotation_file, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        # skip header\n",
    "        for row in reader:\n",
    "            annotations[c][0].append(int(row[0]))  # cell index\n",
    "            annotations[c][1].append(bool(int(row[1])))  # is positive?\n",
    "    print(\"number of annotations for class\", c, \"is\", len(annotations[c][0]))\n",
    "    print(\"number of positive annotations for class\", c, \"is\", sum(annotations[c][1]))\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reformatting the data\n",
    "We can see that, contrary to how most multi-class classification problems are organized, our annotations are binary for each class. However, we would like to use common techniques on multi-class classification, so it would be nice to convert our dataset to the standard format.\n",
    "\n",
    "What is this format? Well, it is defined by two variables `X` and `y`. The matrix `X` is of shape `(A,D)`, where `A` is the total number of annotations and `D` the feature dimension. `X` contains real values. The vector `y` has shape `D`, and contains integers, one representing each class. Note that we have a total of 4 classes `(0,1,2,3)`, because we have the three cell types + the class of cells that are not any of these three types.\n",
    "\n",
    "### Task 1: Consistency\n",
    "We need to check that the data is of good quality. For that, check that the annotations are consistent: this is, check that all the annotations refer to different indices. If there are annotations for the same index, then the annotation should not be contradictory. Each annotation should belong to only one class.\n",
    "\n",
    "If there are any indices that were inconsistently annotated, print them out. \n",
    "\n",
    "### Task 2: Formatting\n",
    "Now that we have ensured consistency, we need to format the labels or annotations in variables `X,y` as described above. For that, create a list of annotated indices, the list of corresponding labels (0,1,2, or 3) and the list of features corresponding to the indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices incohérents ou ayant plusieurs classes :\n",
      "Index 585154 a une incohérence entre les classes lymphocyte : ancienne étiquette = False, nouvelle étiquette = True\n",
      "Index 732406 a une incohérence entre les classes lymphoplasmocyte : ancienne étiquette = True, nouvelle étiquette = False\n",
      "Index 968583 a une incohérence entre les classes plasmocyte : ancienne étiquette = True, nouvelle étiquette = False\n",
      "Index 729897 appartient aux classes : ['lymphoplasmocyte', 'plasmocyte']\n",
      "\n",
      "Nombre total d'incohérences ou d'indices ayant plusieurs classes : 4\n"
     ]
    }
   ],
   "source": [
    "# Initialiser un dictionnaire pour stocker les annotations de toutes les classes par index\n",
    "combined_annotations = {}\n",
    "\n",
    "# Liste pour stocker toutes les incohérences\n",
    "inconsistent_indices = []\n",
    "\n",
    "# Fusionner les annotations pour chaque classe\n",
    "for c in classes:\n",
    "    indices = annotations[c][0]\n",
    "    labels = annotations[c][1]\n",
    "    for idx, label in zip(indices, labels):\n",
    "        if idx not in combined_annotations:\n",
    "            combined_annotations[idx] = {c: label}\n",
    "        else:\n",
    "            if c in combined_annotations[idx] and combined_annotations[idx][c] != label:\n",
    "                # Ajouter l'incohérence au tableau des incohérences\n",
    "                inconsistent_indices.append({\n",
    "                    'index': idx,\n",
    "                    'class': c,\n",
    "                    'existing_label': combined_annotations[idx][c],\n",
    "                    'new_label': label,\n",
    "                    'type': 'incoherent'\n",
    "                })\n",
    "        combined_annotations[idx][c] = label\n",
    "\n",
    "# Détecter les indices ayant plusieurs classes\n",
    "for idx, class_labels in combined_annotations.items():\n",
    "    # Vérifier si l'index appartient à plus d'une classe (labels True pour plusieurs classes)\n",
    "    positive_classes = [cls for cls, label in class_labels.items() if label]\n",
    "    if len(positive_classes) > 1:\n",
    "        # Ajouter l'indice avec plusieurs classes au tableau des incohérences\n",
    "        inconsistent_indices.append({\n",
    "            'index': idx,\n",
    "            'classes': positive_classes,\n",
    "            'type': 'multiple_classes'\n",
    "        })\n",
    "\n",
    "# Afficher les incohérences\n",
    "print(\"Indices incohérents ou ayant plusieurs classes :\")\n",
    "for inconsistency in inconsistent_indices:\n",
    "    if inconsistency['type'] == 'incoherent':\n",
    "        print(f\"Index {inconsistency['index']} a une incohérence entre les classes {inconsistency['class']} : \"\n",
    "              f\"ancienne étiquette = {inconsistency['existing_label']}, nouvelle étiquette = {inconsistency['new_label']}\")\n",
    "    elif inconsistency['type'] == 'multiple_classes':\n",
    "        print(f\"Index {inconsistency['index']} appartient aux classes : {inconsistency['classes']}\")\n",
    "\n",
    "# Résumé\n",
    "if not inconsistent_indices:\n",
    "    print(\"Aucune incohérence détectée.\")\n",
    "else:\n",
    "    print(f\"\\nNombre total d'incohérences ou d'indices ayant plusieurs classes : {len(inconsistent_indices)}\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations[classes[2]][0]\n",
    "729897 in annotations[classes[2]][0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------\n",
      "Nombre d'index avant filtrage : 984007\n",
      "Nombre d'index après filtrage : 984003\n",
      "----------------\n",
      "Le jeu de données filtré a été sauvegardé dans 'true_filtered_cell_dataset.pkl'.\n",
      "Les indices incohérents ont été sauvegardés dans 'true_incoherent_indices.txt'.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# On suppose que les incohérences ont déjà été détectées et stockées dans la variable `incoherences`\n",
    "incoherent_indices = [incoherence['index'] for incoherence in inconsistent_indices]\n",
    "\n",
    "# Charger les données existantes (cell_dataset.pkl)\n",
    "with open('cell_dataset.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# Supposons que 'data['feats']' est un tableau numpy des caractéristiques des cellules\n",
    "# Si 'data['feats']' est un tableau numpy, les indices peuvent être simplement les indices de ligne.\n",
    "cell_indices = np.arange(len(data['feats']))  # Création d'une liste d'indices basée sur la longueur de 'feats'\n",
    "\n",
    "# Filtrer les cellules en excluant celles qui ont des incohérences\n",
    "filtered_feats = [feats for idx, feats in zip(cell_indices, data['feats']) if idx not in incoherent_indices]\n",
    "filtered_cell_indices = [idx for idx in cell_indices if idx not in incoherent_indices]\n",
    "\n",
    "print(\"---------------\")\n",
    "print(f\"Nombre d'index avant filtrage : {len(cell_indices)}\")\n",
    "print(f\"Nombre d'index après filtrage : {len(filtered_cell_indices)}\")\n",
    "print(\"----------------\")\n",
    "\n",
    "# Créer un nouveau dictionnaire avec les données filtrées\n",
    "filtered_data = {\n",
    "    'feats': np.array(filtered_feats),\n",
    "    'indices': np.array(filtered_cell_indices)  # Ajouter les indices filtrés\n",
    "}\n",
    "\n",
    "# Sauvegarder les données filtrées dans un nouveau fichier pkl\n",
    "with open('true_filtered_cell_dataset.pkl', 'wb') as f:\n",
    "    pickle.dump(filtered_data, f)\n",
    "\n",
    "# Enregistrer les indices incohérents dans un fichier texte\n",
    "with open('true_incoherent_indices.txt', 'w') as f:\n",
    "    for idx in incoherent_indices:\n",
    "        f.write(f\"{idx}\\n\")\n",
    "\n",
    "print(f\"Le jeu de données filtré a été sauvegardé dans 'true_filtered_cell_dataset.pkl'.\")\n",
    "print(f\"Les indices incohérents ont été sauvegardés dans 'true_incoherent_indices.txt'.\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'indices filtrés : 984003\n",
      "Nombre d'indices annotés : 987\n",
      "Nombre d'indices non annotés : 983016\n",
      "Nombre d'indices non annotés calculé : 983016\n"
     ]
    }
   ],
   "source": [
    "# Charger les données filtrées\n",
    "with open('true_filtered_cell_dataset.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    features = data['feats']\n",
    "    filtered_indices = set(data['indices'])  # Ensemble des indices filtrés\n",
    "\n",
    "# Identifier les indices des cellules annotées\n",
    "filtered_annotated_indices = set()\n",
    "\n",
    "# S'assurer que les annotations sont uniques et cohérentes\n",
    "for c in classes:\n",
    "    for idx in annotations[c][0]:\n",
    "        # Vérifier si l'indice est bien dans filtered_indices\n",
    "        if idx in filtered_indices:\n",
    "            filtered_annotated_indices.add(idx)\n",
    "\n",
    "# Affichage des résultats\n",
    "print(f\"Nombre d'indices filtrés : {len(filtered_indices)}\")\n",
    "print(f\"Nombre d'indices annotés : {len(filtered_annotated_indices)}\")\n",
    "print(f\"Nombre d'indices non annotés : {len(filtered_indices - filtered_annotated_indices)}\")\n",
    "\n",
    "# Créer les indices des cellules non annotées\n",
    "unlabeled_indices = list(filtered_indices - filtered_annotated_indices)\n",
    "print(f\"Nombre d'indices non annotés calculé : {len(unlabeled_indices)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions de X: (987, 384)\n",
      "Dimensions de y: (987,)\n",
      "\n",
      "Distribution des classes:\n",
      "Classe 0 (lymphocyte): 250 échantillons\n",
      "Classe 1 (lymphoplasmocyte): 122 échantillons\n",
      "Classe 2 (plasmocyte): 118 échantillons\n",
      "Classe 3 (autre): 497 échantillons\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Charger les features du jeu de données filtré\n",
    "with open('true_filtered_cell_dataset.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    features = data['feats']\n",
    "    filtered_indices = data['indices']\n",
    "\n",
    "# Initialiser les listes pour stocker les données formatées\n",
    "X = []  # Features\n",
    "y = []  # Labels\n",
    "used_indices = []  # Pour garder une trace des indices utilisés\n",
    "\n",
    "# Parcourir tous les indices filtrés\n",
    "for idx in filtered_indices:\n",
    "    if idx in combined_annotations:\n",
    "        class_labels = combined_annotations[idx]\n",
    "        # Déterminer la classe de la cellule\n",
    "        positive_classes = [i for i, c in enumerate(classes) if class_labels.get(c, False)]\n",
    "\n",
    "        if len(positive_classes) == 1:\n",
    "            # Si la cellule appartient à une seule classe positive\n",
    "            label = positive_classes[0]\n",
    "        elif len(positive_classes) == 0:\n",
    "            # Si la cellule n'appartient à aucune classe positive\n",
    "            label = 3  # Classe pour \"aucun des trois types\"\n",
    "        else:\n",
    "            # Ne devrait pas arriver car on a filtré les incohérences\n",
    "            continue\n",
    "\n",
    "        # Trouver l'index dans le tableau features filtré\n",
    "        feature_idx = np.where(filtered_indices == idx)[0][0]\n",
    "\n",
    "        # Ajouter les features et le label\n",
    "        X.append(features[feature_idx])\n",
    "        y.append(label)\n",
    "        used_indices.append(idx)\n",
    "\n",
    "# Convertir en arrays numpy\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(f\"Dimensions de X: {X.shape}\")\n",
    "print(f\"Dimensions de y: {y.shape}\")\n",
    "\n",
    "# Afficher la distribution des classes\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "print(\"\\nDistribution des classes:\")\n",
    "for class_idx, count in zip(unique, counts):\n",
    "    if class_idx < 3:\n",
    "        print(f\"Classe {class_idx} ({classes[class_idx]}): {count} échantillons\")\n",
    "    else:\n",
    "        print(f\"Classe {class_idx} (autre): {count} échantillons\")\n",
    "\n",
    "# Sauvegarder les données formatées\n",
    "formatted_data = {\n",
    "    'X': X,\n",
    "    'y': y,\n",
    "    'indices': used_indices,\n",
    "    'class_names': classes + ('other',)\n",
    "}\n",
    "\n",
    "with open('true_formatted_cell_dataset.pkl', 'wb') as f:\n",
    "    pickle.dump(formatted_data, f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'indices filtrés : 984003\n",
      "Nombre d'indices annotés : 987\n",
      "Nombre d'indices non annotés calculé : 983016\n",
      "Nombre d'indices non annotés après calcul de la différence : 983016\n",
      "Nombre d'indices non annotés après validation : 983012\n",
      "Le jeu de données non annoté a été sauvegardé dans 'unlabeled_cell_dataset.pkl'.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Charger les données filtrées\n",
    "with open('true_filtered_cell_dataset.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    features = data['feats']\n",
    "    filtered_indices = set(data['indices'])  # Indices filtrés\n",
    "\n",
    "# Calcul des indices annotés\n",
    "annotated_indices = set()\n",
    "for c in classes:\n",
    "    for idx in annotations[c][0]:\n",
    "        if idx in filtered_indices:  # Vérifier que l'indice fait bien partie du jeu de données filtré\n",
    "            annotated_indices.add(idx)\n",
    "\n",
    "# Vérifier le nombre d'indices annotés et non annotés\n",
    "num_filtered = len(filtered_indices)\n",
    "num_annotated = len(annotated_indices)\n",
    "num_unlabeled = num_filtered - num_annotated\n",
    "\n",
    "print(f\"Nombre d'indices filtrés : {num_filtered}\")\n",
    "print(f\"Nombre d'indices annotés : {num_annotated}\")\n",
    "print(f\"Nombre d'indices non annotés calculé : {num_unlabeled}\")\n",
    "\n",
    "# Assurez-vous qu'il n'y a pas de doublons ou d'indices erronés\n",
    "if num_unlabeled != 983016:\n",
    "    print(f\"Erreur : Le nombre de cellules non annotées ({num_unlabeled}) ne correspond pas à l'attendu (983016).\")\n",
    "\n",
    "# Extraire les indices non annotés\n",
    "unlabeled_indices = list(filtered_indices - annotated_indices)  # Différence entre les indices filtrés et annotés\n",
    "\n",
    "# Vérification du nombre d'indices non annotés\n",
    "print(f\"Nombre d'indices non annotés après calcul de la différence : {len(unlabeled_indices)}\")\n",
    "\n",
    "# S'assurer que les indices sont dans la bonne plage (0 à len(features)-1)\n",
    "unlabeled_indices = [idx for idx in unlabeled_indices if idx < len(features)]\n",
    "\n",
    "# Vérification que les indices sont valides\n",
    "print(f\"Nombre d'indices non annotés après validation : {len(unlabeled_indices)}\")\n",
    "\n",
    "# Créer le jeu de données non annoté\n",
    "X_unlabeled = features[unlabeled_indices]  # Extraire les features des cellules non annotées\n",
    "\n",
    "# Sauvegarder le jeu de données non annoté\n",
    "unlabeled_data = {\n",
    "    'X_unlabeled': X_unlabeled,\n",
    "    'indices': unlabeled_indices\n",
    "}\n",
    "\n",
    "with open('unlabeled_cell_dataset.pkl', 'wb') as f:\n",
    "    pickle.dump(unlabeled_data, f)\n",
    "\n",
    "print(f\"Le jeu de données non annoté a été sauvegardé dans 'unlabeled_cell_dataset.pkl'.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structure des données : dict_keys(['X_unlabeled', 'indices'])\n"
     ]
    }
   ],
   "source": [
    "with open('unlabeled_cell_dataset.pkl', 'rb') as file:\n",
    "    unlabeled_data = pickle.load(file)\n",
    "print(\"Structure des données :\", unlabeled_data.keys())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total de cellules non étiquetées disponibles : 983012\n",
      "Le jeu de données réduit avec 100 000 cellules non étiquetées a été sauvegardé dans 'reduced_unlabeled_cell_dataset.pkl'.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Charger le jeu de données non annoté\n",
    "with open('unlabeled_cell_dataset.pkl', 'rb') as f:\n",
    "    unlabeled_data = pickle.load(f)\n",
    "    X_unlabeled = unlabeled_data['X_unlabeled']\n",
    "    unlabeled_indices = unlabeled_data['indices']\n",
    "\n",
    "# Vérifier le nombre total de cellules non étiquetées disponibles\n",
    "num_unlabeled_cells = len(X_unlabeled)\n",
    "print(f\"Nombre total de cellules non étiquetées disponibles : {num_unlabeled_cells}\")\n",
    "\n",
    "# Si le nombre de cellules non étiquetées est suffisant, en sélectionner 100 000\n",
    "if num_unlabeled_cells >= 100000:\n",
    "    # Sélectionner aléatoirement 100 000 indices\n",
    "    selected_indices = np.random.choice(num_unlabeled_cells, 100000, replace=False)\n",
    "    X_selected = X_unlabeled[selected_indices]  # Extraire les features correspondants aux indices sélectionnés\n",
    "    selected_indices_list = list(np.array(unlabeled_indices)[selected_indices])  # Obtenir les indices sélectionnés\n",
    "\n",
    "    # Sauvegarder le jeu de données réduit avec 100 000 exemples\n",
    "    reduced_unlabeled_data = {\n",
    "        'X_unlabeled': X_selected,\n",
    "        'indices': selected_indices_list\n",
    "    }\n",
    "\n",
    "    with open('reduced_unlabeled_cell_dataset.pkl', 'wb') as f:\n",
    "        pickle.dump(reduced_unlabeled_data, f)\n",
    "\n",
    "    print(\"Le jeu de données réduit avec 100 000 cellules non étiquetées a été sauvegardé dans 'reduced_unlabeled_cell_dataset.pkl'.\")\n",
    "else:\n",
    "    print(f\"Erreur : Le nombre de cellules non étiquetées ({num_unlabeled_cells}) est insuffisant pour extraire 100 000 exemples.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and evaluation \n",
    "Now we have our data ready!\n",
    "\n",
    "Go ahead and implement a multi-class classifier. Don't forget to do train-test split or cross-validation to report performance. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entraînement du modèle...\n",
      "Modèle entraîné avec succès.\n",
      "Taille de l'ensemble d'entraînement :  789\n",
      "Taille de l'ensemble de test :  198\n",
      "\n",
      "Résultats de la validation croisée : \n",
      "--------------------------------------------------\n",
      "Accuracy moyenne : 0.658 (+/- 0.024\n",
      "\n",
      "Performances sur l'ensemble de test : \n",
      "--------------------------------------------------\n",
      "\n",
      "Rapport de classification détaillé : \n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      lymphocyte       0.70      0.91      0.79        46\n",
      "lymphoplasmocyte       0.38      1.00      0.55        15\n",
      "      plasmocyte       0.52      0.92      0.67        25\n",
      "           other       0.96      0.46      0.63       112\n",
      "\n",
      "        accuracy                           0.67       198\n",
      "       macro avg       0.64      0.82      0.66       198\n",
      "    weighted avg       0.80      0.67      0.66       198\n",
      "\n",
      "Modèle sauvegardé dans 'knn_model(k=28).pkl'.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "# Charger les données formatées\n",
    "with open('true_formatted_cell_dataset.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    # Extraire les features et les labels\n",
    "    X = data['X']\n",
    "    y = data['y']\n",
    "    class_names = data['class_names']\n",
    "\n",
    "# Séparer les données en ensembles d'entraînement et de test (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialiser le classificateur K-Nearest Neighbors avec 5 voisins\n",
    "k = 28 #int(math.sqrt(len(X_train)))\n",
    "#print(f\"Nombre de points d'entrainement : {len(X_train)}\")\n",
    "#print(f\"Valeur de k calculée : {k}\")\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=k, weights='uniform')\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(model, X_train_scaled, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Entraîner le modèle\n",
    "print(\"Entraînement du modèle...\")\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print(\"Modèle entraîné avec succès.\")\n",
    "\n",
    "# Prédictions sur l'ensemble de test\n",
    "y_pred_test = model.predict(X_test_scaled)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title(f'Matrice de confusion - KNN (k={k})')\n",
    "plt.ylabel('Vraie classe')\n",
    "plt.xlabel('Classe prédite')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'confusion_matrix_KNN(k={k}).png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Taille de l'ensemble d'entraînement : \", X_train.shape[0])\n",
    "print(\"Taille de l'ensemble de test : \", X_test.shape[0])\n",
    "print(\"\\nRésultats de la validation croisée : \")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Accuracy moyenne : {scores.mean():.3f} (+/- {scores.std()*2:.3f}\")\n",
    "print(\"\\nPerformances sur l'ensemble de test : \")\n",
    "print(\"-\" * 50)\n",
    "print(\"\\nRapport de classification détaillé : \")\n",
    "print(classification_report(y_test, y_pred_test, target_names=class_names))\n",
    "\n",
    "# Sauvegarder le modèle entraîné pour utilisation future\n",
    "with open(f'knn_model(k={k}).pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "print(f\"Modèle sauvegardé dans 'knn_model(k={k}).pkl'.\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le modèle a testé 198 index.\n",
      "Le jeu de données contient un total de 987 index.\n"
     ]
    }
   ],
   "source": [
    "# Nombre d'index testés (taille de y_test)\n",
    "num_tested_indices = len(y_test)\n",
    "\n",
    "# Nombre total d'index (taille de y)\n",
    "num_total_indices = len(y)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(f\"Le modèle a testé {num_tested_indices} index.\")\n",
    "print(f\"Le jeu de données contient un total de {num_total_indices} index.\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and evaluation over IRIS\n",
    "\n",
    "Now replicate the same multi class classification method but over the IRIS dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
